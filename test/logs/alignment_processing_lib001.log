finding positions of the duplicate reads in the file...
  sorted 2130 end pairs
     and 696 single ends (among them 0 unmatched pairs)
  collecting indices of duplicate reads...   done in 1 ms
  found 534 duplicates
collected list of positions in 0 min 0 sec
removing duplicates...
total time elapsed: 0 min 0 sec
