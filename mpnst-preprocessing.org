* MPNST Sequencing Read Pre-processing                              :bioinfo:
** Setup
*** Repository
#+begin_src bash
mkdir -p "${repo}/workflow/scripts"            
#+end_src
*** Bash
**** Configurations
- Local (by $HOSTNAME)
  - jeff-mac-book
    #+begin_src bash :noweb yes :tangle ./config/jeff-mac-book.sh
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8

#####################################################################
###   Bash configuration script for MPNST fragmentomics project   ###
#####################################################################

# Host-local variables
data_dir=/mnt/ris/aadel/mpnst
mntpt=/mnt/ris/aadel
repo=/home/jeszyman/repos/mpnst-preprocessing
sif_dir=/home/jeszyman/sing_containers
threads=8

<<bash_common_config>>
    #+end_src
  - [[file:config/jeszyman-work.sh][jeszyman-work]]
    #+begin_src bash :noweb yes :tangle ./config/jeszyman-work.sh 
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8

#####################################################################
###   Bash configuration script for MPNST fragmentomics project   ###
#####################################################################

# Host-local variables
data_dir=/mnt/ris/aadel/mpnst
mntpt=/mnt/ris/aadel
repo=/home/jeszyman/repos/mpnst-preprocessing
sif_dir=/home/jeszyman/sing_containers
threads=8

<<bash_common_config>>
    #+end_src
  - [[file:config/aclm350.sh][aclm350]]
    #+begin_src bash :noweb yes :tangle ./config/aclm350.sh 
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8

################################################################################
###   Bash configuration script for MPNST fragmentomics project on ACLM350   ###
################################################################################

# Host-local variables
data_dir=/mnt/ris/aadel/mpnst
mntpt=/mnt/ris/aadel
repo=/home/jszymanski/repos/mpnst-preprocessing
sif_dir=/home/jszymanski/sing_containers
threads=40

<<bash_common_config>>
    #+end_src
- Common
  #+name: bash_common_config
  #+begin_src bash :noweb yes
# Check git file hook is read-able
if [ -r "${repo}/.git/hooks/precommit" ]; then
   echo "Git size check is read-able"
else
    echo
    "Git size check is not read-able"
    exit 1
fi
          
# Check mount point  
if grep -qs $mntpt /proc/mounts; then
    echo "RIS storage mounted."
else
    echo "RIS storage NOT mounted!!!"
fi

# Check local singularity build present
if [ -r ${sif_dir}/frag.sif ]; then
    echo "Local singularity file present"
else
    echo "Local singularity file not found."
fi

# Check if local singularity container is present and up-to-date
if [ -r "${HOME}/sing_containers/biotools.sif" ]; then
    echo "Local biotools singularity container exists"
else
    echo "No local biotools singularity container, attempting to fetch..."
    mkdir -p "${HOME}/sing_containers"
    cp /mnt/ris/aadel/jeszyman/sing_containers/biotools.sif "${HOME}/sing_containers"
fi 

if [ ${HOME}/sing_containers/biotools.sif -ot /mnt/ris/aadel/jeszyman/sing_containers/biotools.sif ];
then
    echo "Local biotools container out of date, updating..."
    cp /mnt/ris/aadel/jeszyman/sing_containers/biotools.sif "${HOME}/sing_containers"
else
    echo "Local biotools singularity container is up to date"
fi

sing_biotools() {
    singularity shell --bind /mnt:/mnt ~/sing_containers/biotools.sif            
}

launch_frag() { 
    if [ -f /.dockerenv ]; then
        echo "shell already in docker, exiting";
        exit 1;
    else
        docker run --env HOME=${HOME} --hostname ${HOSTNAME} --interactive --tty --volume /home/:/home/ --volume /tmp/:/tmp/ --volume /mnt/:/mnt/ --user $(id -u ${USER}) -w "$repo" jeszyman/frag /bin/bash;
    fi
}
#+end_src           

*** Git and github
#+begin_src bash
repo=/home/jeszyman/repos/mpnst-preprocessing
cd $repo

git init
git add -A 
git commit -m "first commit"

git remote add origin git@github.com:jeszyman/mpnst-preprocessing.git
git branch -M master
git push -u origin master
#+end_src

=======
>>>>>>> 13100f2e636cf025b3635db5ccf481b075cdf1a5
*** Docker and singularity - none; use biotools submodule
#+begin_src bash :tangle ./src/launch_singularity_shell.sh
singularity shell --bind /mnt:/mnt ~/sing_containers/biotools.sif            
#+end_src


*** Snakemake
- consider a workdir: "/output/dir" 
**** Configuration YAMLs
- [[file:config/aclm350.yaml][ACLM350]]
  #+begin_src bash :tangle config/aclm350.yaml
container: "/home/jszymanski/sing_containers/frag.sif"
data_dir: "/mnt/ris/aadel/mpnst"
threads: 40
repo: "/drive3/users/jszymanski/repos/mpnst-preprocessing"
cap_extract_script: "/drive3/users/jszymanski/repos/mpnst-preprocessing/workflow/scripts/cp_fastq_extract_auto.pl"
#+end_src
- [[file:config/common.yaml][common]]
  #+begin_src bash :tangle config/common.yaml
cap_extract_script: "src/cp_fastq_extract_auto.pl"
inputs_dir: "/mnt/ris/aadel/mpnst/inputs"
demultiplex_dir: "/mnt/ris/aadel/mpnst/cappseq/demultiplexed"
hg38_fasta: "GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai"
hg38_fasta_ftp: "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai"
hg38_bwa_index_ftp: "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bwa_index.tar.gz"
hg38_bwa_index_zip: "GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bwa_index.tar.gz"
ref_dir: "/mnt/ris/aadel/mpnst/ref"
log_dir: "/mnt/ris/aadel/mnpst/logs"
#+end_src
- repo_test
  #+begin_src bash :tangle ./config/repo_test.yaml
container: "/home/jeszyman/sing_containers/biotools.sif"        
raw_fq_dir: "test/fastq"
qc_dir: "test/qc"
log_dir: "test/logs"
threads: 4
inputs_dir: "test/inputs"
processed_fq_dir: "test/processed-fastq"
unpr_fq_dir: "test/unpaired-fastq"
bwa_index: "test/ref/chr8"
bam_dir: "test/bam"
rename_dir: "test/cappseq_fastq"
extracted_dir: "test/extracted_fastq"
fq_symlink_dir: "test/symlink_fastq"
#+end_src
**** Run commands
:PROPERTIES:
:header-args: :tangle no
:END:
#+begin_src bash :tangle ./src/smk_repo_test.sh
eval "$(command conda 'shell.bash' 'hook' 2> /dev/null)"

conda activate snakemake
source config/${HOSTNAME}.sh

snakemake \
    --configfile config/repo_test.yaml \
    --cores $threads \
    --directory ${repo} \
    --dry-run \
    --rerun-incomplete \
    --use-singularity \
    --snakefile ./workflow/read_qc.smk

    &&
    
    snakemake \
        --configfile config/repo_test.yaml \
        --cores $threads \
        --directory ${repo} \
        --rerun-incomplete \
        --use-singularity \
        -F \
        --snakefile ./workflow/read_qc.smk 
#+end_src
#+begin_src bash :tangle ./src/smk_run.sh
#!/bin/bash
#########1#########2#########3#########4#########5#########6#########7#########8
eval "$(command conda 'shell.bash' 'hook' 2> /dev/null)"
####################################
###   Choose and Run Snakefile   ###
####################################

# Setup
#set -euxov pipefail

source config/${HOSTNAME}.sh
echo "The following `*.smk` archives were found; select one:"

# set the prompt used by select, replacing "#?"
PS3="Use number to select an option"

select filename in ./workflow/*.smk

do
    if [[ "$filename" == "" ]]
    then
        echo "'$REPLY' is not a valid number"
        continue
    fi
    echo $filename
    select run_option in dry_run normal force_final force_all
    do
        echo selected $run_option
        case $run_option in
            dry_run)
                conda activate snakemake
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    --dry-run \
                    --rerun-incomplete \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                ;;
            normal) 
                conda activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;
            force_final)
                conda activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --force \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --force \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
            force_all)
                conda activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                                            ;;
                        yes)
                nohup snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
        esac
        break
    done
    break
done
#+end_src

#+begin_src bash :tangle ./src/smk_test.sh
#!/bin/bash

eval "$(command conda 'shell.bash' 'hook' 2> /dev/null)"

echo "The following `*.smk` archives were found; select one:"

# set the prompt used by select, replacing "#?"
PS3="Use number to select an option"

select filename in ./workflow/*.smk

do
    if [[ "$filename" == "" ]]
    then
        echo "'$REPLY' is not a valid number"
        continue
    fi
    conda activate snakemake
    snakemake --dry-run --snakefile $filename \
              --configfile config/${HOSTNAME}.yaml \
              --cores $threads \
              --directory ${repo} \
              --rerun-incomplete \
              --singularity-args "--bind $mntpt:$mntpt" \
              --use-singularity 
done
#+end_src

#+begin_src bash :tangle ./src/smk_run.sh
#!/bin/bash
#########1#########2#########3#########4#########5#########6#########7#########8

####################################
###   Choose and Run Snakefile   ###
####################################

# Setup
#set -euxov pipefail
source config/${HOSTNAME}.sh
echo "The following `*.smk` archives were found; select one:"

# set the prompt used by select, replacing "#?"
PS3="Use number to select an option"

select filename in ./workflow/*.smk

do
    if [[ "$filename" == "" ]]
    then
        echo "'$REPLY' is not a valid number"
        continue
    fi
    echo $filename
    select run_option in dry_run normal force_final force_all
    do
        echo selected $run_option
        case $run_option in
            dry_run)
                source activate snakemake
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    --dry-run \
                    --rerun-incomplete \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                ;;
            normal) 
                source activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;
            force_final)
                source activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --force \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --force \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
            force_all)
                source activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                                            ;;
                        yes)
                nohup snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
        esac
        break
    done
    break
done
#+end_src

#+begin_src bash
#cd ~/repos/mpnst
conda activate snakemake
source config/"${HOSTNAME}.sh"                                                   

nohup snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --directory "${repo}" \
  --cores 10 \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflows/cappseq.smk \
  --use-singularity 


nohup snakemake \
    --configfile config/${HOSTNAME}.yaml \
    --cores $threads \
    --directory "${repo}" \
    --printshellcmds \
    --singularity-args "--bind $mntpt:$mntpt" \
    --snakefile workflow/frag.smk \
    --use-singularity 


nohup snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity \
  --rerun-incomplete
#+end_src

#+begin_src bash
#cd ~/repos/mpnst
conda activate snakemake
source config/"${HOSTNAME}.sh"

snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --dry-run \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity 

snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity 


snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity \
  --rulegraph | dot -Tpdf > $repo/resources/frag_rules.pdf
#+end_src

** CAPPseq WGS fastq processing                                         :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/cappseq.smk
:END:
- starts with DE-multiplexed capp fastqs as inputs
*** Setup integration testing
#+begin_src bash
source config/${HOSTNAME}.sh            

\rm -rf "${repo}/test/cappseq_fastq"
mkdir -p "${repo}/test/cappseq_fastq"

zcat /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT.fastq.gz | head -n 100000 > "${repo}/test/cappseq_fastq/capp1_R1.fastq"
zcat /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT.fastq.gz | head -n 100000 > "${repo}/test/cappseq_fastq/capp1_R2.fastq"
zcat /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_ATCG.fastq.gz | head -n 100000 > "${repo}/test/cappseq_fastq/capp2_R1.fastq"
zcat /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_ATCG.fastq.gz | head -n 100000 > "${repo}/test/cappseq_fastq/capp2_R2.fastq"
for file in "${repo}/test/cappseq_fastq/*.fastq"; do gzip $file; done
#+end_src
*** TODO [[file:workflow/cappseq.smk][Snakefile]]                                                      :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/cappseq.smk
:END:              
**** Smk preamble
#+begin_src snakemake
configfile: "./config/common.yaml"
READ_ID, = glob_wildcards(config["rename_dir"] + "/{id}_R1.fastq.gz")
#+end_src              
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["extracted_dir"] + "/{read_id}_extract_{read}.fastq.gz", read_id=READ_ID, read=["R1","R2"]),	
#+end_src                            
***** INPROCESS Extract cappseq barcodes
- Snakemake
  #+begin_src snakemake
rule extract_cappseq_barcodes:
    input:
        read1 = config["rename_dir"] + "/{read_id}_R1.fastq.gz",
        read2 = config["rename_dir"] + "/{read_id}_R2.fastq.gz",
    output:
        read1 = temp(config["rename_dir"] + "/{read_id}_R1.fastq"),
        read2 = temp(config["rename_dir"] + "/{read_id}_R2.fastq"),
        read1mv = config["extracted_dir"] + "/{read_id}_R1.fastq",
        read2mv = config["extracted_dir"] + "/{read_id}_R2.fastq",
    resources:
        mem_mb=10000	
    shell:
        """
        perl {config[cap_extract_script]} {input.read1} {input.read2}
        cp {output.read1} {output.read1mv}
        cp {output.read2} {output.read2mv}
        """
#+end_src
***** WAITING Fix headers                                          :smk_rule:
- Snakemake
#+begin_src snakemake
rule fix_headers:
    input:
        config["extracted_dir"] + "/{read_id}_{read}.fastq",
    output:
        unzip = config["extracted_dir"] + "/{read_id}_extract_{read}.fastq",
        zip = config["extracted_dir"] + "/{read_id}_extract_{read}.fastq.gz",	
    shell:
        """
        workflow/scripts/test.sh {input} {output.unzip}
        pigz -c -p {config[threads]} {output.unzip} > {output.zip} 
        """
#+end_src

***** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
****** Rename                                                      :smk_rule:
- Snakemake
#+begin_src snakemake
rule rename:
    input: config["demultiplex_dir"] + "/{id}.fastq.gz",
    output: config["rename_dir"] + "/{id}.fastq.gz",
    shell:
        """
        ln -s {input} {output}
        """
#+end_src
- [[file:./workflow/scripts/rename.sh][Base script]]
#+begin_src bash
#!/usr/bin/env bash
cp 
#+end_src
****** Rename                                                      :smk_rule:
- Snakemake
#+begin_src snakemake
rule rename:
    input:
        read1 =config["demultiplex_dir"] + "/{capp_id1}_R1_{capp_id2}.fastq.gz",
        read2 =config["demultiplex_dir"] + "/{capp_id1}_R1_{capp_id2}.fastq.gz",	
    output:
        read1 =config["rename_dir"] + "/{capp_id1}_{capp_id2}_R1.fastq.gz",
        read2 =config["rename_dir"] + "/{capp_id1}_{capp_id2}_R2.fastq.gz",	
    shell:
        """
        ln --symbolic --relative {input.read1} {output.read1}
        ln --symbolic --relative {input.read2} {output.read2}
        """
#+end_src
- [[file:./workflows/scripts/rename.sh][Base script]]
,  #+begin_src bash :tangle ./workflows/scripts/rename.sh
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8               
###
###    SCRIPT TITLE   ###                
###

#+end_src
**** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
***** Smk preamble
#+begin_src snakemake
IDS, = glob_wildcards(config["data_dir"] + "{id}_R1.fastq.gz")            
#+end_src              
***** Smk rules
****** All rule
#+begin_src snakemake
rule all:
    input:
                    
#+end_src                            

****** Extract CAPPseq barcodes                                    :smk_rule:
- Snakemake
  #+begin_src snakemake
rule extract_cappseq_barcodes:
    input:
        read1 = config["data_dir"] + "/inputs/cappseq-fastqs/
        bcode_fq_R2 = config["data_dir"] + "/tmp_capp_fastq/{capp_id}_R2.fastq.gz"
    params:
        outdir = config["data_dir"] + "/tmp/extract_fastq/"
    output:
        extract_fq_R1 = config["data_dir"] + "/tmp_extract_fastq/{capp_id}_R1.fastq"
        extract_fq_R2 = config["data_dir"] + "/tmp_extract_fastq/{capp_id}_R2.fastq"
    shell:
        """
        scripts/extract_cappseq_barcodes.sh {input.bcode_fq_R1} {input.bcode_fq_R2} {params.outdir}
        """
#+end_src

*** Dev
- Barcode extraction
  #+begin_src bash
# Setup test
# \rm -rf /mnt/ris/aadel/mpnst/cappseq/barcode
# \rm -rf /mnt/ris/aadel/mpnst/cappseq/rename
# \rm -rf /mnt/ris/aadel/mpnst/cappseq/headerfix

# mkdir -p /mnt/ris/aadel/mpnst/cappseq/barcode
# mkdir -p /mnt/ris/aadel/mpnst/cappseq/rename
# mkdir -p /mnt/ris/aadel/mpnst/cappseq/headerfix

# cp /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT.fastq.gz /mnt/ris/aadel/mpnst/cappseq/rename/            

# cp /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT.fastq.gz /mnt/ris/aadel/mpnst/cappseq/rename/            

# rename s/\.fastq.gz/_R1.fastq.gz/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT.fastq.gz 

# rename s/\.fastq.gz/_R2.fastq.gz/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT.fastq.gz 

# rename s/_R1_/_/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT_R1.fastq.gz

# rename s/_R2_/_/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT_R2.fastq.gz

# perl ~/repos/mpnst-preprocessing/src/cp_fastq_extract_auto.pl \
#      /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq.gz \
#      /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq.gz

# cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq

# cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq

# pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq.gz

# pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq.gz

#########1#########2#########3#########4#########5#########6#########7#########8

# Setup test

\rm -rf /mnt/ris/aadel/mpnst/cappseq/barcode
\rm -rf /mnt/ris/aadel/mpnst/cappseq/rename
\rm -rf /mnt/ris/aadel/mpnst/cappseq/headerfix

demultiplex_dir=/mnt/ris/aadel/mpnst/cappseq/demultiplexed
rename_dir=/mnt/ris/aadel/mpnst/cappseq/rename
cap_extract_script=/drive3/users/jszymanski/repos/mpnst-preprocessing/workflows/scripts/cp_fastq_extract_auto.pl

mkdir -p $rename_dir

# rule 1
for file in ${demultiplex_dir}/*.fastq.gz;
do
    cp $file $rename_dir
done

cp ${demultiplex_dir}/${read1} $rename_dir
cp ${demultiplex_dir}/${read2} $rename_dir
rename s/\.fastq.gz/_R1.fastq.gz/g ${rename_dir}/${read1}
rename s/\.fastq.gz/_R2.fastq.gz/g ${rename_dir}/${read2}
rename s/_R1_/_/g ${rename_dir}/${rename1}
rename s/_R2_/_/g ${rename_dir}/${rename2}

read1="new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT.fastq.gz"
read2="new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT.fastq.gz"
rename1="new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT_R1.fastq.gz"
rename2="new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT_R2.fastq.gz"
rename11="new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq.gz"
rename22="new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq.gz"


nohub
for file in /mnt/ris/aadel/mpnst/cappseq/rename/*_R1.fastq.gz;
do
    r2=$(echo $file | sed -e "s/R1.fastq.gz/R2.fastq.gz/g")
    perl ~/repos/mpnst-preprocessing/workflows/scripts/cp_fastq_extract_auto.pl $file $r2
done


#2 rule 2
perl $cap_extract_script ${rename_dir}/${rename11} ${rename_dir}/${rename22}
# note- &> /tmp/test.txt doesn't work, have to move the log file manually
mkdir -p $headerfix

# rule 3

cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq

cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq

pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq.gz

pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq.gz
#+end_src
  #+begin_src bash
mkdir -p ~/repos/mpnst-preprocessing/src
cp ~/repos/mpnst-data/src/cp-fastq-extract-auto.pl ~/repos/mpnst-preprocessing/src/cp_fastq_extract_auto.pl

launch_frag() { 
    if [ -f /.dockerenv ]; then
        echo "shell already in docker, exiting";
        exit 1;
    else
        docker run --env HOME=${HOME} --hostname ${HOSTNAME} --interactive --tty --volume /home/:/home/ --volume /tmp/:/tmp/ --volume /mnt/:/mnt/ --user $(id -u ${USER}) -w "$repo" jeszyman/frag /bin/bash;
    fi
}

launch_frag

#########1#########2#########3#########4#########5#########6#########7#########8

# Make test data
\rm -rf /mnt/ris/aadel/mpnst/tmp/capptest
mkdir -p /mnt/ris/aadel/mpnst/tmp/capptest/cappraw
mkdir -p /mnt/ris/aadel/mpnst/tmp/capptest/nobar
mkdir -p /mnt/ris/aadel/mpnst/tmp/capptest/headfix

zcat /mnt/ris/aadel/mpnst/inputs/cappseq-fastq/new_HiSeq-19_L006001_ACAC_R1.fastq.gz | head -n 10000 > /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R1.fastq
zcat /mnt/ris/aadel/mpnst/inputs/cappseq-fastq/new_HiSeq-19_L006001_ACAC_R2.fastq.gz | head -n 10000 > /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R2.fastq
gzip --force --keep /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/*.fastq

#########1#########2#########3#########4#########5#########6#########7#########8

capp_extract(){
    # The cp_fastq_extract_auto.pl will overwrite existing outputs
    dir=$(dirname $2)
    base=$(basename -s _R1.fastq.gz $2)
    perl $1 $2 $3
    pigz -c -p $4 "${dir}/${base}_R1.fastq" > "${5}/${base}_R1.fastq.gz"
    pigz -c -p $4 "${dir}/${base}_R2.fastq" > "${5}/${base}_R2.fastq.gz"
    for file in "${5}/${base}_R1.fastq.gz"; do
        zcat $file | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > "${6}/${base}_clip_R1.fastq"
    done
    for file in "${5}/${base}_R2.fastq.gz"; do
        zcat $file | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > "${6}/${base}_clip_R2.fastq"
    done
    pigz -p $4 "${6}/${base}_clip_R1.fastq"
    pigz -p $4 "${6}/${base}_clip_R2.fastq"    
}

capp_extract \
    ~/repos/mpnst-preprocessing/src/cp_fastq_extract_auto.pl \
    /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R1.fastq.gz \
    /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R2.fastq.gz \
    4 \
    /mnt/ris/aadel/mpnst/tmp/capptest/nobar \
    /mnt/ris/aadel/mpnst/tmp/capptest/headfix

    




# headers change from 
# @E00521:255:H3HJ5CCX2:6:1101:2443:2909:CGTAACAC:1:N:0:CGTAACAC:TA:TA
# to
# @E00521:255:H3HJ5CCX2:6:1101:2443:2909:CGTAACAC

#+end_src
- For barcode-extracted fastqs, correct headers for use with bwa  
  #+begin_src bash
source config/jeszyman-server.sh
launch_frag

source config/jeszyman-server.sh
mkdir $data_dir/tmp_capp_fastq

cp $data_dir/inputs/cappseq-fastq/* $data_dir/tmp_capp_fastq

cd $data_dir/tmp_capp_fastq

rename -n s/\.fastq.gz/_R1.fastq.gz/g *_R1_*.fastq.gz
rename -n s/\.fastq.gz/_R2.fastq.gz/g *_R2_*.fastq.gz

rename -n s/_R1_/_/g *R1.fastq.gz
rename -n s/_R2_/_/g *R2.fastq.gz


#+end_src
- Demultiplexing
  #+begin_src bash

## Functions
cappseq_demultiplex() {
  if [ "$#" -ne 3 ]; then      
      printf "___Wrapper function to demultiplex MedGenome CAPP-Seq libraries___\n
          Inputs:\n
          1 = Multiplexed .fastq.gz\n
          2 = Output directory\n
          3 = sample2barcode\n
          Returns: Demultiplexed fastqs named as <BASENAME>_<BARCODE>.fastq.gz"
      fi
  base=`basename -s .fastq.gz $1`
  if ["$2/$base*" -nt $1 ]; then
      echo "$base already demultiplexed"
  else
      echo "All inputs exist, running demultiplexing of $1"        
      perl /drive3/users/jszymanski/repos/cappseq/bin/cp-fastq-demultiplex.pl $1 $2 $3
  fi    
}

            
## Functions
cappseq_demultiplex() {
  base=`basename -s .fastq.gz $1`
  if ["$2/$base*" -nt $1 ]; then
      echo "$base already demultiplexed"
  else
      echo "All inputs exist, running demultiplexing of $1"        
      perl ~/repos/mpnst-preprocessing/src/cp_fastq_demultiplex.pl $1 $2 $3
  fi    
}

# here trying without a specific barcode

perl ~/repos/mpnst-preprocessing/src/cp_fastq_demultiplex.pl /mnt/ris/aadel/capp-seq/capp-fastqs/HiSeqW38,39,40,41,42/new_HiSeq42_Undetermined_R6000281_L008_R1_001.fastq.gz /mnt/ris/aadel/mpnst/tmp/demulti 
#+end_src
** TODO Pre-processing and alignment
*** [[file:./workflow/read_qc.smk][Snakefile]]                                                           :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/read_qc.smk
:END:              
**** Smk preamble
#+begin_src snakemake
container: config["container"]
import pandas as pd
import numpy as np

samples = pd.read_table(config["inputs_dir"] + "/samples.tsv")
sampledict = dict(zip(samples['new_name'], samples['old_name']))

wildcard_constraints:
    read_id='|'.join([re.escape(x) for x in sampledict.keys()]),
    
#+end_src              
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["processed_fq_dir"] + "/{read_id}_proc_{read}.fastq.gz", read_id = sampledict.keys(), read = ["R1","R2"]),
        expand(config["unpr_fq_dir"] + "/{read_id}_unpr_R1.fastq.gz", read_id = sampledict.keys(), read = ["R1","R2"]),
        expand(config["qc_dir"] + "/{read_id}_{read}_fastqc.html", read_id = sampledict.keys(), read = ["R1","R2"]),
        expand(config["qc_dir"] + "/{read_id}_proc_{read}_fastqc.html", read_id = sampledict.keys(), read = ["R1","R2"]),
	expand(config["bam_dir"] + "/{read_id}_dedup_sort.bam", read_id = sampledict.keys())
#+end_src                            
***** Rename :smk_rule:
- Snakemake
#+begin_src snakemake
rule rename:
    params:
        old_sample_id=lambda wcs: sampledict[wcs.f],
    output:
        read1=config["fq_symlink_dir"] + "/{f}_R1.fastq.gz",
        read2=config["fq_symlink_dir"] + "/{f}_R2.fastq.gz",	
    shell:
        """
        if [ -f {output.read1} ]; then \\rm {output.read1}; fi
        if [ -f {output.read2} ]; then \\rm {output.read2}; fi
        ln -s --relative "{config[raw_fq_dir]}/{params.old_sample_id}_R1.fastq.gz" {output.read1}
        ln -s --relative "{config[raw_fq_dir]}/{params.old_sample_id}_R2.fastq.gz" {output.read2}
        """
#+end_src

***** Read preprocessing                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule trimmomatic:
    input:
        read1 = config["fq_symlink_dir"] + "/{fq_id}_R1.fastq.gz",
        read2 = config["fq_symlink_dir"] + "/{fq_id}_R2.fastq.gz",
    params:
        adapter_fasta = config["inputs_dir"] + "/TruSeq3-PE.fa",
    output:
        read1 = config["processed_fq_dir"] + "/{fq_id}_proc_R1.fastq.gz",
        read1_unpr = config["unpr_fq_dir"] + "/{fq_id}_unpr_R1.fastq.gz",
        read2 = config["processed_fq_dir"] + "/{fq_id}_proc_R2.fastq.gz",
        read2_unpr = config["unpr_fq_dir"] + "/{fq_id}_unpr_R2.fastq.gz",	
    log:
        int = config["log_dir"] + "/trimmomatic_trimlog_{fq_id}.log",
        main = config["log_dir"] + "/trimmomatic_{fq_id}.log",
    shell:
        """
        workflow/scripts/trimmomatic.sh \
        {config[threads]} \
        {log.int} \
        {input.read1} \
        {input.read2} \
        {output.read1} \
        {output.read1_unpr} \
        {output.read2} \
        {output.read2_unpr} \
        {params.adapter_fasta} &> {log.main}
        """
#+end_src
- [[file:workflow/scripts/trimmomatic.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/trimmomatic.sh
#!/usr/bin/env bash
trimmomatic PE \
            -threads $1 \
            -trimlog $2 \
            $3 $4 \
            $5 $6 \
            $7 $8 \
            ILLUMINACLIP:"$9":2:30:10 \
            LEADING:10 TRAILING:10 MAXINFO:50:0.97 MINLEN:20
#+end_src
- Reference
  - Trimmomatic parameters based on Taylor's parameters ([[https://mail.google.com/mail/u/0/#search/sundby+fastq/FMfcgzGmvLWSbsmhDsffvSSWfjWdQhhR?projector=1&messagePartId=0.1][email]])
  - https://github.com/AAFC-BICoE/snakemake-trimmomatic/blob/master/Snakefile
***** FastQC                                                       :smk_rule:
- Snakemake
  #+begin_src snakemake
rule fastqc:
    input: 
        raw=config["fq_symlink_dir"] + "/{read_id}_{read}.fastq.gz",
	proc=config["processed_fq_dir"] + "/{read_id}_proc_{read}.fastq.gz",
    params: 
        out_dir = config["qc_dir"],
    output:
        raw_html = config["qc_dir"] + "/{read_id}_{read}_fastqc.html",
        proc_html = config["qc_dir"] + "/{read_id}_proc_{read}_fastqc.html", 	
    log: 
        raw = config["log_dir"] + "/fastqc_raw_{read_id}_{read}.log",
        proc = config["log_dir"] + "/fastqc_proc_{read_id}_{read}.log",	
    shell:
        """
	fastqc --outdir {params.out_dir} \
	--quiet \
	--threads {config[threads]} {input.raw} &> {log}
	fastqc --outdir {params.out_dir} \
	--quiet \
	--threads {config[threads]} {input.proc} &> {log}
        """
- https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html see multiext
- [[file:./workflows/scripts/fastqc.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/fastqc.sh
fastqc --outdir $2 \
       --quiet \
       --threads $3 $1
#+end_src
***** TODO Alignment 
- Snakemake
  #+begin_src snakemake
rule align:
    input:
        read1 = config["processed_fq_dir"] + "/{fq_id}_proc_R1.fastq.gz",
        read2 = config["processed_fq_dir"] + "/{fq_id}_proc_R2.fastq.gz",
    output:
        config["bam_dir"] + "/{fq_id}.sam",
    log:
        config["log_dir"] + "/align_{fq_id}.log"
    shell:
        """
        bwa mem -M -t 4 {config[bwa_index]} {input.read1} {input.read2} > {output}
	"""
#+end_src
***** Rename bams
- Snakemake
  #+begin_src snakemake

rule all: 
    input:
        expand(config["rename_dir"] + "/{newname}.bam", newname=libids)

rule rename_bams:
    input:
        config["bam_dir"] + "/{sample_id}.bam"
    output: 
        config["rename_dir"] + "/{newname}.bam"
    shell:
        """
	cp {input} {output}
	"""

rule move_and_rename_fastqs:
    input:  fastq = lambda w: units_table[units_table.SampleSM == w.sample]
    output: temp(SCRATCH + "/01RAW_fqs/{sample}")
    log:    SCRATCH + "/00logs/01RAW_fqs/{sample}.log"
    shell:
            """cp {input.fastq} {output} 2> {log}"""

samples= list(units_table.SampleSM.unique())
# rule move_and_rename_fastqs:
#     input:  fastq = lambda w: sample_df[sample_df.sampleID == w.sample].fastq.tolist()
#     output: temp(SCRATCH + "/01RAW_fqs/{sample}")
#     log:    SCRATCH + "/00logs/01RAW_fqs/{sample}.log"
#     shell:
#             """cp {input.fastq} {output} 2> {log}"""

#+end_src
***** TODO Alignment processing
- Snakemake
  #+begin_src snakemake
rule alignment_processing:
    input:
        config["bam_dir"] + "/{fq_id}.sam",
    output:
        bam = config["bam_dir"] + "/{fq_id}.bam",
        dedup = config["bam_dir"] + "/{fq_id}_dedup.bam",
        sort = config["bam_dir"] + "/{fq_id}_dedup_sort.bam",
        index = config["bam_dir"] + "/{fq_id}_dedup_sort.bam.bai",
    log:
        config["log_dir"] + "/alignment_processing_{fq_id}.log"
    shell:
        """
        sambamba view -t {config[threads]} -S -f bam {input} > {output.bam}
        sambamba markdup -r -t {config[threads]} {output.bam} {output.dedup}
        sambamba sort -t {config[threads]} {output.dedup} -o {output.sort}
        sambamba index -t {config[threads]} {output.sort}
        """
#+end_src
**** Hold
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
**** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
rule all:
    input:

rule fastqc:
    input: 
        raw = config["fastq_dir"] + "/{fastq_id}.faster.gz"
        processed = config
    output:
    shell:
    """
    fastqc
    """

rule seq_preprocess:
    input:
    output:
    shell:
        """
        trimmomatic
        """

**** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
- ideas
  - add # # TODO setup via fastqc metrics check
    - # for read1 in $fastqdir/*_R1.fastq.gz; do
      #     base=`basename -s _R1.fastq.gz ${read1}`
      #     filesize=$(wc -c <"$bamdir/${base}.bam")
      #     if [ $minimum_bam_size -ge $filesize ]; then
      #         echo $base >> /drive3/users/jszymanski/repos/mpnst/data/small_bams        
      #     fi
      # done
      # readarray -t small_bam < /drive3/users/jszymanski/repos/mpnst/data/small_bams         
***** Ideas
  - filter to min file size && expected by manual spreadsheet
  - fastqs too small (< 500 Mb)
    #+begin_src bash :results replace
  find /mnt/ris/aadel/mpnst/inputs/cappseq-fastq -size -500M
  #+end_src

*** Integration testing setup
#+begin_src bash
cd ~/repos/mpnst-preprocessing/
source config/${HOSTNAME}.sh

\rm -rf "${repo}/test"
mkdir -p "${repo}/test/fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/19_2_082_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst1_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/19_2_082_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst1_R2.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/25_2_072_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst2_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/25_2_072_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst2_R2.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/37_JS0050CD112717_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex1_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/37_JS0050CD112717_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex1_R2.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/30_JS0044CD112818_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex2_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/30_JS0044CD112818_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex2_R2.fastq"
for file in "${repo}/test/fastq/*.fastq"; do gzip $file; done

mkdir -p "${repo}/test/inputs"

wget --directory-prefix="${repo}/test/inputs/" https://raw.githubusercontent.com/usadellab/Trimmomatic/main/adapters/TruSeq3-PE.fa

wget --directory-prefix="${repo}/test/inputs/" https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz

mkdir -p ${repo}/test/ref

zcat "${repo}/test/inputs/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz" | grep -A 2000 chr8 > ${repo}/test/inputs/chr8.fa

\rm ${repo}/test/inputs/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz

singularity shell --bind /mnt:/mnt ~/sing_containers/biotools.sif

source config/${HOSTNAME}.sh

bwa index -p ${repo}/test/ref/chr8 ${repo}/test/inputs/chr8.fa

#bwa mem -t 4 ${repo}/test/ref/chr8 ${repo}/test/processed-fastq/mpnst1_proc_R1.fastq.gz ${repo}/test/processed-fastq/mpnst1_proc_R1.fastq.gz

exit
#+end_src
** TODO Alignment QC
** TODO Downsample Bams
#+name: downsample_bam
#+begin_src bash :tangle ./src/functions.sh
function downsample_bam {

## Calculate the sampling factor based on the intended number of reads:
FACTOR=$(samtools idxstats $1 | cut -f3 | awk -v COUNT=$2 'BEGIN {total=0} {total += $1} END {print COUNT/total}')

if [[ $FACTOR > 1 ]]; then 
    echo "DS reads exceeds total for $1"
else
    sambamba view -s $FACTOR -f bam -l 5 $1    
fi
}

#+end_src

#+name: downsample_bam
#+begin_src bash :tangle ./src/functions.sh
function downsample_bam {

## Calculate the sampling factor based on the intended number of reads:
FACTOR=$(samtools idxstats $1 | cut -f3 | awk -v COUNT=$2 'BEGIN {total=0} {total += $1} END {print COUNT/total}')

if [[ $FACTOR > 1 ]]; then 
    echo "DS reads exceeds total for $1"
else
    sambamba view -s $FACTOR -f bam -l 5 $1    
fi
}

#+end_src

* Local Variables
#+TODO: WAITING(w@) TODO(t) INPROCESS(p) | CLOSEOUT DONE(d!) DELEGATED(@) CANCELED(@)  
#+PROPERTY: LOGGING nil
#+PROPERTY: header-args:bash :tangle-mode (identity #o777)
#+property: header-args    :cache yes
#+property: header-args    :exports none            
#+property: header-args    :eval never-export
#+property: header-args    :results silent            
#+property: header-args    :tangle no
#+startup: shrink




