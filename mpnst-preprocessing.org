* MPNST Sequencing Read Pre-processing                              :bioinfo:
** Setup
*** Repository
#+begin_src bash
mkdir -p "${repo}/workflow/scripts"            
#+end_src
*** Bash
**** Configurations
- Local (by $HOSTNAME)
  - [[file:config/jeszyman-work.sh][jeszyman-work]]
    #+begin_src bash :noweb yes :tangle ./config/jeszyman-work.sh 
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8

#####################################################################
###   Bash configuration script for MPNST fragmentomics project   ###
#####################################################################

# Host-local variables
data_dir=/mnt/ris/aadel/mpnst
mntpt=/mnt/ris/aadel
repo=/home/jeszyman/repos/mpnst-preprocessing
sif_dir=/home/jeszyman/sing_containers
threads=8

<<bash_common_config>>
    #+end_src
  - [[file:config/aclm350.sh][aclm350]]
    #+begin_src bash :noweb yes :tangle ./config/aclm350.sh 
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8

################################################################################
###   Bash configuration script for MPNST fragmentomics project on ACLM350   ###
################################################################################

# Host-local variables
data_dir=/mnt/ris/aadel/mpnst
mntpt=/mnt/ris/aadel
repo=/home/jszymanski/repos/mpnst-preprocessing
sif_dir=/home/jszymanski/sing_containers
threads=40

<<bash_common_config>>
    #+end_src
- Common
  #+name: bash_common_config
  #+begin_src bash :noweb yes
# Check git file hook is read-able
if [ -r "${repo}/.git/hooks/precommit" ]; then
   echo "Git size check is read-able"
else
    echo
    "Git size check is not read-able"
    exit 1
fi
          
# Check mount point  
if grep -qs $mntpt /proc/mounts; then
    echo "RIS storage mounted."
else
    echo "RIS storage NOT mounted, exiting."
    exit 1
fi

# Check local singularity build present
if [ -r ${sif_dir}/frag.sif ]; then
    echo "Local singularity file present"
else
    echo "Local singularity file not found."
fi

# Check if local singularity container is present and up-to-date
if [ -r "${HOME}/sing_containers/biotools.sif" ]; then
    echo "Local biotools singularity container exists"
else
    echo "No local biotools singularity container, attempting to fetch..."
    mkdir -p "${HOME}/sing_containers"
    cp /mnt/ris/aadel/jeszyman/sing_containers/biotools.sif "${HOME}/sing_containers"
fi 

if [ ${HOME}/sing_containers/biotools.sif -ot /mnt/ris/aadel/jeszyman/sing_containers/biotools.sif ];
then
    echo "Local biotools container out of date, updating..."
    cp /mnt/ris/aadel/jeszyman/sing_containers/biotools.sif "${HOME}/sing_containers"
else
    echo "Local biotools singularity container is up to date"
fi

sing_biotools() {
    singularity shell --bind /mnt:/mnt ~/sing_containers/biotools.sif            
}

launch_frag() { 
    if [ -f /.dockerenv ]; then
        echo "shell already in docker, exiting";
        exit 1;
    else
        docker run --env HOME=${HOME} --hostname ${HOSTNAME} --interactive --tty --volume /home/:/home/ --volume /tmp/:/tmp/ --volume /mnt/:/mnt/ --user $(id -u ${USER}) -w "$repo" jeszyman/frag /bin/bash;
    fi
}
#+end_src           

*** Git and github
#+begin_src bash
repo=/home/jeszyman/repos/mpnst-preprocessing
cd $repo

git init
git add -A 
git commit -m "first commit"

git remote add origin git@github.com:jeszyman/mpnst-preprocessing.git
git branch -M master
git push -u origin master
#+end_src

=======
>>>>>>> 13100f2e636cf025b3635db5ccf481b075cdf1a5
*** Docker and singularity - none; use biotools submodule
#+begin_src bash :tangle ./src/launch_singularity_shell.sh
singularity shell --bind /mnt:/mnt ~/sing_containers/biotools.sif            
#+end_src


*** Snakemake
**** Configuration YAMLs
- [[file:config/aclm350.yaml][ACLM350]]
  #+begin_src bash :tangle config/aclm350.yaml
container: "/home/jszymanski/sing_containers/frag.sif"
data_dir: "/mnt/ris/aadel/mpnst"
threads: 40
repo: "/drive3/users/jszymanski/repos/mpnst-preprocessing"
cap_extract_script: "/drive3/users/jszymanski/repos/mpnst-preprocessing/workflow/scripts/cp_fastq_extract_auto.pl"
#+end_src
- [[file:config/common.yaml][common]]
  #+begin_src bash :tangle config/common.yaml
inputs_dir: "/mnt/ris/aadel/mpnst/inputs"
demultiplex_dir: "/mnt/ris/aadel/mpnst/cappseq/demultiplexed"
rename_dir: "/mnt/ris/aadel/mpnst/cappseq/rename"
extracted_dir: "/mnt/ris/aadel/mpnst/cappseq/extracted"
hg38_fasta: "GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai"
hg38_fasta_ftp: "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai"
hg38_bwa_index_ftp: "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bwa_index.tar.gz"
hg38_bwa_index_zip: "GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bwa_index.tar.gz"
ref_dir: "/mnt/ris/aadel/mpnst/ref"
log_dir: "/mnt/ris/aadel/mnpst/logs"
#+end_src
- repo_test
  #+begin_src bash :tangle ./config/repo_test.yaml
container: "/home/jeszyman/sing_containers/biotools.sif"        
raw_fq_dir: "test/fastq"
qc_dir: "test/qc"
log_dir: "test/logs"
threads: 4
inputs_dir: "test/inputs"
processed_fq_dir: "test/processed-fastq"
unpr_fq_dir: "test/unpaired-fastq"
#+end_src
**** Run commands
:PROPERTIES:
:header-args: :tangle no
:END:
#+begin_src bash :tangle ./src/smk_repo_test.sh
eval "$(command conda 'shell.bash' 'hook' 2> /dev/null)"

conda activate snakemake
source config/${HOSTNAME}.sh

snakemake \
    --configfile config/repo_test.yaml \
    --cores $threads \
    --directory ${repo} \
    --dry-run \
    --rerun-incomplete \
    --use-singularity \
    --snakefile ./workflow/read_qc.smk &&
    snakemake \
        --configfile config/repo_test.yaml \
        --cores $threads \
        --directory ${repo} \
        --rerun-incomplete \
        --use-singularity \
        -F \
        --snakefile ./workflow/read_qc.smk 
#+end_src
#+begin_src bash :tangle ./src/smk_run.sh
#!/bin/bash
#########1#########2#########3#########4#########5#########6#########7#########8
eval "$(command conda 'shell.bash' 'hook' 2> /dev/null)"
####################################
###   Choose and Run Snakefile   ###
####################################

# Setup
#set -euxov pipefail

source config/${HOSTNAME}.sh
echo "The following `*.smk` archives were found; select one:"

# set the prompt used by select, replacing "#?"
PS3="Use number to select an option"

select filename in ./workflow/*.smk

do
    if [[ "$filename" == "" ]]
    then
        echo "'$REPLY' is not a valid number"
        continue
    fi
    echo $filename
    select run_option in dry_run normal force_final force_all
    do
        echo selected $run_option
        case $run_option in
            dry_run)
                conda activate snakemake
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    --dry-run \
                    --rerun-incomplete \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                ;;
            normal) 
                conda activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;
            force_final)
                conda activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --force \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --force \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
            force_all)
                conda activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                                            ;;
                        yes)
                nohup snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
        esac
        break
    done
    break
done
#+end_src

#+begin_src bash :tangle ./src/smk_test.sh
#!/bin/bash

eval "$(command conda 'shell.bash' 'hook' 2> /dev/null)"

echo "The following `*.smk` archives were found; select one:"

# set the prompt used by select, replacing "#?"
PS3="Use number to select an option"

select filename in ./workflow/*.smk

do
    if [[ "$filename" == "" ]]
    then
        echo "'$REPLY' is not a valid number"
        continue
    fi
    conda activate snakemake
    snakemake --dry-run --snakefile $filename \
              --configfile config/${HOSTNAME}.yaml \
              --cores $threads \
              --directory ${repo} \
              --rerun-incomplete \
              --singularity-args "--bind $mntpt:$mntpt" \
              --use-singularity 
done
#+end_src

#+begin_src bash :tangle ./src/smk_run.sh
#!/bin/bash
#########1#########2#########3#########4#########5#########6#########7#########8

####################################
###   Choose and Run Snakefile   ###
####################################

# Setup
#set -euxov pipefail
source config/${HOSTNAME}.sh
echo "The following `*.smk` archives were found; select one:"

# set the prompt used by select, replacing "#?"
PS3="Use number to select an option"

select filename in ./workflow/*.smk

do
    if [[ "$filename" == "" ]]
    then
        echo "'$REPLY' is not a valid number"
        continue
    fi
    echo $filename
    select run_option in dry_run normal force_final force_all
    do
        echo selected $run_option
        case $run_option in
            dry_run)
                source activate snakemake
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    --dry-run \
                    --rerun-incomplete \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                ;;
            normal) 
                source activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;
            force_final)
                source activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                            snakemake \
                                --configfile config/${HOSTNAME}.yaml \
                                --cores $threads \
                                --directory ${repo} \
                                --force \
                                --singularity-args "--bind $mntpt:$mntpt" \
                                --use-singularity \
                                --snakefile $filename
                            ;;
                        yes)
                            nohup snakemake \
                                  --configfile config/${HOSTNAME}.yaml \
                                  --cores $threads \
                                  --directory ${repo} \
                                  --force \
                                  --singularity-args "--bind $mntpt:$mntpt" \
                                  --use-singularity \
                                  --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
            force_all)
                source activate snakemake
                select nohup_option in no yes
                do
                    case $nohup_option in
                        no)                                          
                
                snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                                            ;;
                        yes)
                nohup snakemake \
                    --configfile config/${HOSTNAME}.yaml \
                    --cores $threads \
                    --directory ${repo} \
                    -F \
                    --singularity-args "--bind $mntpt:$mntpt" \
                    --use-singularity \
                    --snakefile $filename
                            ;;
                    esac
                done                
                ;;            
        esac
        break
    done
    break
done
#+end_src

#+begin_src bash
#cd ~/repos/mpnst
conda activate snakemake
source config/"${HOSTNAME}.sh"                                                   

nohup snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --directory "${repo}" \
  --cores 10 \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflows/cappseq.smk \
  --use-singularity 


nohup snakemake \
    --configfile config/${HOSTNAME}.yaml \
    --cores $threads \
    --directory "${repo}" \
    --printshellcmds \
    --singularity-args "--bind $mntpt:$mntpt" \
    --snakefile workflow/frag.smk \
    --use-singularity 


nohup snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity \
  --rerun-incomplete
#+end_src

#+begin_src bash
#cd ~/repos/mpnst
conda activate snakemake
source config/"${HOSTNAME}.sh"

snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --dry-run \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity 

snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity 


snakemake \
  --configfile config/${HOSTNAME}.yaml \
  --cores $threads \
  --directory "${repo}" \
  --printshellcmds \
  --singularity-args "--bind $mntpt:$mntpt" \
  --snakefile workflow/frag.smk \
  --use-singularity \
  --rulegraph | dot -Tpdf > $repo/resources/frag_rules.pdf
#+end_src

** CAPPseq WGS fastq processing                                         :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/cappseq.smk
:END:
add resources call to capppseq perl 
- starts with DE-multiplexed capp fastqs as inputs
- Barcode extraction
  #+begin_src bash
# Setup test
# \rm -rf /mnt/ris/aadel/mpnst/cappseq/barcode
# \rm -rf /mnt/ris/aadel/mpnst/cappseq/rename
# \rm -rf /mnt/ris/aadel/mpnst/cappseq/headerfix

# mkdir -p /mnt/ris/aadel/mpnst/cappseq/barcode
# mkdir -p /mnt/ris/aadel/mpnst/cappseq/rename
# mkdir -p /mnt/ris/aadel/mpnst/cappseq/headerfix

# cp /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT.fastq.gz /mnt/ris/aadel/mpnst/cappseq/rename/            

# cp /mnt/ris/aadel/mpnst/cappseq/demultiplexed/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT.fastq.gz /mnt/ris/aadel/mpnst/cappseq/rename/            

# rename s/\.fastq.gz/_R1.fastq.gz/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT.fastq.gz 

# rename s/\.fastq.gz/_R2.fastq.gz/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT.fastq.gz 

# rename s/_R1_/_/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT_R1.fastq.gz

# rename s/_R2_/_/g /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT_R2.fastq.gz

# perl ~/repos/mpnst-preprocessing/src/cp_fastq_extract_auto.pl \
#      /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq.gz \
#      /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq.gz

# cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq

# cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq

# pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq.gz

# pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq.gz

#########1#########2#########3#########4#########5#########6#########7#########8

# Setup test

\rm -rf /mnt/ris/aadel/mpnst/cappseq/barcode
\rm -rf /mnt/ris/aadel/mpnst/cappseq/rename
\rm -rf /mnt/ris/aadel/mpnst/cappseq/headerfix

demultiplex_dir=/mnt/ris/aadel/mpnst/cappseq/demultiplexed
rename_dir=/mnt/ris/aadel/mpnst/cappseq/rename
cap_extract_script=/drive3/users/jszymanski/repos/mpnst-preprocessing/workflows/scripts/cp_fastq_extract_auto.pl

mkdir -p $rename_dir

# rule 1
for file in ${demultiplex_dir}/*.fastq.gz;
do
    cp $file $rename_dir
done

cp ${demultiplex_dir}/${read1} $rename_dir
cp ${demultiplex_dir}/${read2} $rename_dir
rename s/\.fastq.gz/_R1.fastq.gz/g ${rename_dir}/${read1}
rename s/\.fastq.gz/_R2.fastq.gz/g ${rename_dir}/${read2}
rename s/_R1_/_/g ${rename_dir}/${rename1}
rename s/_R2_/_/g ${rename_dir}/${rename2}

read1="new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT.fastq.gz"
read2="new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT.fastq.gz"
rename1="new_HiSeq-W44_Undetermined_R6000324_L004_R1_001_AGGT_R1.fastq.gz"
rename2="new_HiSeq-W44_Undetermined_R6000324_L004_R2_001_AGGT_R2.fastq.gz"
rename11="new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq.gz"
rename22="new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq.gz"


nohub
for file in /mnt/ris/aadel/mpnst/cappseq/rename/*_R1.fastq.gz;
do
    r2=$(echo $file | sed -e "s/R1.fastq.gz/R2.fastq.gz/g")
    perl ~/repos/mpnst-preprocessing/workflows/scripts/cp_fastq_extract_auto.pl $file $r2
done


#2 rule 2
perl $cap_extract_script ${rename_dir}/${rename11} ${rename_dir}/${rename22}
# note- &> /tmp/test.txt doesn't work, have to move the log file manually
mkdir -p $headerfix

# rule 3

cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq

cat /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R2.fastq | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq

pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R1.fastq.gz

pigz -c -p 16 /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq > /mnt/ris/aadel/mpnst/cappseq/headerfix/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_headfix_R2.fastq.gz
#+end_src
  #+begin_src bash
mkdir -p ~/repos/mpnst-preprocessing/src
cp ~/repos/mpnst-data/src/cp-fastq-extract-auto.pl ~/repos/mpnst-preprocessing/src/cp_fastq_extract_auto.pl

launch_frag() { 
    if [ -f /.dockerenv ]; then
        echo "shell already in docker, exiting";
        exit 1;
    else
        docker run --env HOME=${HOME} --hostname ${HOSTNAME} --interactive --tty --volume /home/:/home/ --volume /tmp/:/tmp/ --volume /mnt/:/mnt/ --user $(id -u ${USER}) -w "$repo" jeszyman/frag /bin/bash;
    fi
}

launch_frag

#########1#########2#########3#########4#########5#########6#########7#########8

# Make test data
\rm -rf /mnt/ris/aadel/mpnst/tmp/capptest
mkdir -p /mnt/ris/aadel/mpnst/tmp/capptest/cappraw
mkdir -p /mnt/ris/aadel/mpnst/tmp/capptest/nobar
mkdir -p /mnt/ris/aadel/mpnst/tmp/capptest/headfix

zcat /mnt/ris/aadel/mpnst/inputs/cappseq-fastq/new_HiSeq-19_L006001_ACAC_R1.fastq.gz | head -n 10000 > /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R1.fastq
zcat /mnt/ris/aadel/mpnst/inputs/cappseq-fastq/new_HiSeq-19_L006001_ACAC_R2.fastq.gz | head -n 10000 > /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R2.fastq
gzip --force --keep /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/*.fastq

#########1#########2#########3#########4#########5#########6#########7#########8

capp_extract(){
    # The cp_fastq_extract_auto.pl will overwrite existing outputs
    dir=$(dirname $2)
    base=$(basename -s _R1.fastq.gz $2)
    perl $1 $2 $3
    pigz -c -p $4 "${dir}/${base}_R1.fastq" > "${5}/${base}_R1.fastq.gz"
    pigz -c -p $4 "${dir}/${base}_R2.fastq" > "${5}/${base}_R2.fastq.gz"
    for file in "${5}/${base}_R1.fastq.gz"; do
        zcat $file | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > "${6}/${base}_clip_R1.fastq"
    done
    for file in "${5}/${base}_R2.fastq.gz"; do
        zcat $file | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > "${6}/${base}_clip_R2.fastq"
    done
    pigz -p $4 "${6}/${base}_clip_R1.fastq"
    pigz -p $4 "${6}/${base}_clip_R2.fastq"    
}

capp_extract \
    ~/repos/mpnst-preprocessing/src/cp_fastq_extract_auto.pl \
    /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R1.fastq.gz \
    /mnt/ris/aadel/mpnst/tmp/capptest/cappraw/test_R2.fastq.gz \
    4 \
    /mnt/ris/aadel/mpnst/tmp/capptest/nobar \
    /mnt/ris/aadel/mpnst/tmp/capptest/headfix

    




# headers change from 
# @E00521:255:H3HJ5CCX2:6:1101:2443:2909:CGTAACAC:1:N:0:CGTAACAC:TA:TA
# to
# @E00521:255:H3HJ5CCX2:6:1101:2443:2909:CGTAACAC

#+end_src
- d
  #+begin_src bash
mkdir -p /mnt/ris/aadel/mpnst/cappseq/rename

ln -s /mnt/ris/aadel/mpnst/cappseq//demultiplexed/new_HiSeq-W44* /mnt/ris/aadel/mpnst/cappseq/rename

rename 's/([^_]+)_([^_]+)_([^_]+)_([^_]+)\.fastq.gz$/$1_$3_$4_$2.fastq.gz/' /mnt/ris/aadel/mpnst/cappseq/rename/*.fastq.gz

mkdir -p /mnt/ris/aadel/mpnst/cappseq/barcode

repo=/home/jeszyman/repos/mpnst-preprocessing
cd $repo

perl ../cappseq/bin/cp-fastq-extract-auto.pl /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq.gz \
     /mnt/ris/aadel/mpnst/cappseq/rename/new_HiSeq-W44_Undetermined_R6000324_L004_001_AGGT_R1.fastq.gz


#+end_src
- Demultiplexing
  #+begin_src bash

## Functions
cappseq_demultiplex() {
  if [ "$#" -ne 3 ]; then      
      printf "___Wrapper function to demultiplex MedGenome CAPP-Seq libraries___\n
          Inputs:\n
          1 = Multiplexed .fastq.gz\n
          2 = Output directory\n
          3 = sample2barcode\n
          Returns: Demultiplexed fastqs named as <BASENAME>_<BARCODE>.fastq.gz"
      fi
  base=`basename -s .fastq.gz $1`
  if ["$2/$base*" -nt $1 ]; then
      echo "$base already demultiplexed"
  else
      echo "All inputs exist, running demultiplexing of $1"        
      perl /drive3/users/jszymanski/repos/cappseq/bin/cp-fastq-demultiplex.pl $1 $2 $3
  fi    
}

            
## Functions
cappseq_demultiplex() {
  base=`basename -s .fastq.gz $1`
  if ["$2/$base*" -nt $1 ]; then
      echo "$base already demultiplexed"
  else
      echo "All inputs exist, running demultiplexing of $1"        
      perl ~/repos/mpnst-preprocessing/src/cp_fastq_demultiplex.pl $1 $2 $3
  fi    
}

# here trying without a specific barcode

perl ~/repos/mpnst-preprocessing/src/cp_fastq_demultiplex.pl /mnt/ris/aadel/capp-seq/capp-fastqs/HiSeqW38,39,40,41,42/new_HiSeq42_Undetermined_R6000281_L008_R1_001.fastq.gz /mnt/ris/aadel/mpnst/tmp/demulti 
#+end_src
- For barcode-extracted fastqs, correct headers for use with bwa  
  #+begin_src bash
source config/jeszyman-server.sh
launch_frag

source config/jeszyman-server.sh
mkdir $data_dir/tmp_capp_fastq

cp $data_dir/inputs/cappseq-fastq/* $data_dir/tmp_capp_fastq

cd $data_dir/tmp_capp_fastq

rename -n s/\.fastq.gz/_R1.fastq.gz/g *_R1_*.fastq.gz
rename -n s/\.fastq.gz/_R2.fastq.gz/g *_R2_*.fastq.gz

rename -n s/_R1_/_/g *R1.fastq.gz
rename -n s/_R2_/_/g *R2.fastq.gz


#+end_src
*** [[file:workflow/cappseq.smk][Snakefile]] :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/cappseq.smk
:END:              
**** Smk preamble
#+begin_src snakemake
configfile: "./config/common.yaml"
READ_ID, = glob_wildcards(config["rename_dir"] + "/{id}_R1.fastq.gz")
#+end_src              
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["extracted_dir"] + "/{read_id}_R1.fastq", read_id=READ_ID),
        expand(config["extracted_dir"] + "/{read_id}_R2.fastq", read_id=READ_ID),
        expand(config["headfix_dir"] + "/{read_id}_{read}.fastq", read_id=READ_ID, read=["R1", "R2"]),	
#+end_src                            
***** INPROCESS Extract cappseq barcodes
- Snakemake
  #+begin_src snakemake
rule extract_cappseq_barcodes:
    input:
        read1 = config["rename_dir"] + "/{read_id}_R1.fastq.gz",
        read2 = config["rename_dir"] + "/{read_id}_R2.fastq.gz",
    output:
        read1 = config["rename_dir"] + "/{read_id}_R1.fastq",
        read2 = config["rename_dir"] + "/{read_id}_R2.fastq",	
        read1mv = config["extracted_dir"] + "/{read_id}_R1.fastq",
        read2mv = config["extracted_dir"] + "/{read_id}_R2.fastq",
    shell:
        """
        perl {config[cap_extract_script]} {input.read1} {input.read2}
        mv {output.read1} {output.read1mv}
        mv {output.read2} {output.read2mv}
        """
#+end_src
***** WAITING Fix headers                                          :smk_rule:
- Snakemake
#+begin_src snakemake
rule fix_headers:
    input:
	config["extracted_dir"] + "/{read_id}_{read}.fastq",
    output:
        unzip = config["headfix_dir"] + "/{read_id}_{read}.fastq",
	zip = config["headfix_dir"] + "/{read_id}_{read}.fastq.gz",
    shell:
        """
        cat {input} | awk '{if(NR%4==1){print substr($0, 1, length($0)-21)}else{print $0}}' > ${output.unzip}
        pigz -c -p {config[threads]} {output.unzip} > {output.zip} 
        """
#+end_src

***** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
****** Rename                                                      :smk_rule:
- Snakemake
#+begin_src snakemake
rule rename:
    input: config["demultiplex_dir"] + "/{id}.fastq.gz",
    output: config["rename_dir"] + "/{id}.fastq.gz",
    shell:
        """
        ln -s {input} {output}
        """
#+end_src
- [[file:./workflow/scripts/rename.sh][Base script]]
#+begin_src bash
#!/usr/bin/env bash
cp 
#+end_src
**** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
***** Smk preamble
#+begin_src snakemake
IDS, = glob_wildcards(config["data_dir"] + "{id}_R1.fastq.gz")            
#+end_src              
***** Smk rules
****** All rule
#+begin_src snakemake
rule all:
    input:
                    
#+end_src                            

****** Extract CAPPseq barcodes                                    :smk_rule:
- Snakemake
  #+begin_src snakemake
rule extract_cappseq_barcodes:
    input:
        read1 = config["data_dir"] + "/inputs/cappseq-fastqs/
        bcode_fq_R2 = config["data_dir"] + "/tmp_capp_fastq/{capp_id}_R2.fastq.gz"
    params:
        outdir = config["data_dir"] + "/tmp/extract_fastq/"
    output:
        extract_fq_R1 = config["data_dir"] + "/tmp_extract_fastq/{capp_id}_R1.fastq"
        extract_fq_R2 = config["data_dir"] + "/tmp_extract_fastq/{capp_id}_R2.fastq"
    shell:
        """
        scripts/extract_cappseq_barcodes.sh {input.bcode_fq_R1} {input.bcode_fq_R2} {params.outdir}
        """
#+end_src

** TODO Read QC and pre-processing
*** Integration testing setup
#+begin_src bash
cd ~/repos/mpnst-preprocessing/
source config/${HOSTNAME}.sh

\rm -rf "${repo}/test"
mkdir -p "${repo}/test/fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/19_2_082_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst1_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/19_2_082_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst1_R2.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/25_2_072_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst2_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/MPNST/25_2_072_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/mpnst2_R2.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/37_JS0050CD112717_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex1_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/37_JS0050CD112717_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex1_R2.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/30_JS0044CD112818_R1.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex2_R1.fastq"
zcat /mnt/ris/aadel/mpnst/inputs/PN/30_JS0044CD112818_R2.fastq.gz | head -n 100000 > "${repo}/test/fastq/plex2_R2.fastq"
for file in "${repo}/test/fastq/*.fastq"; do gzip $file; done

mkdir -p "${repo}/test/inputs"

wget --directory-prefix="${repo}/test/inputs/" https://raw.githubusercontent.com/usadellab/Trimmomatic/main/adapters/TruSeq3-PE.fa
#+end_src
*** [[file:./workflow/read_qc.smk][Snakefile]]:smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/read_qc.smk
:END:              
**** Smk preamble
#+begin_src snakemake
container: config["container"]

FQ_ID_RAW, = glob_wildcards(config["raw_fq_dir"] + "/{id}_R1.fastq.gz")
#+end_src              
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["processed_fq_dir"] + "/{fq_id}_proc_R1.fastq.gz", fq_id=FQ_ID_RAW),
        expand(config["processed_fq_dir"] + "/{fq_id}_proc_R2.fastq.gz", fq_id=FQ_ID_RAW),
        expand(config["unpr_fq_dir"] + "/{fq_id}_unpr_R1.fastq.gz", fq_id=FQ_ID_RAW),
        expand(config["unpr_fq_dir"] + "/{fq_id}_unpr_R2.fastq.gz", fq_id=FQ_ID_RAW),
        expand(config["qc_dir"] + "/{fq_id}_{read}_fastqc.html", fq_id=FQ_ID_RAW, read=["R1", "R2"]),
        expand(config["qc_dir"] + "/{fq_id}_proc_{read}_fastqc.html", fq_id=FQ_ID_RAW, read=["R1", "R2"]),
#+end_src                            
***** Read preprocessing                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule trimmomatic:
    input:
        read1 = config["raw_fq_dir"] + "/{fq_id}_R1.fastq.gz",
        read2 = config["raw_fq_dir"] + "/{fq_id}_R2.fastq.gz",
    params:
        adapter_fasta = config["inputs_dir"] + "/TruSeq3-PE.fa",
    output:
        read1 = config["processed_fq_dir"] + "/{fq_id}_proc_R1.fastq.gz",
        read1_unpr = config["unpr_fq_dir"] + "/{fq_id}_unpr_R1.fastq.gz",
        read2 = config["processed_fq_dir"] + "/{fq_id}_proc_R2.fastq.gz",
        read2_unpr = config["unpr_fq_dir"] + "/{fq_id}_unpr_R2.fastq.gz",	
    log:
        int = config["log_dir"] + "/trimmomatic_trimlog_{fq_id}.log",
        main = config["log_dir"] + "/trimmomatic_{fq_id}.log",
    shell:
        """
        workflow/scripts/trimmomatic.sh \
        {config[threads]} \
        {log.int} \
        {input.read1} \
        {input.read2} \
        {output.read1} \
        {output.read1_unpr} \
        {output.read2} \
        {output.read2_unpr} \
        {params.adapter_fasta} &> {log.main}
        """
#+end_src
- [[file:workflow/scripts/trimmomatic.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/trimmomatic.sh
#!/usr/bin/env bash
trimmomatic PE \
            -threads $1 \
            -trimlog $2 \
            $3 $4 \
            $5 $6 \
            $7 $8 \
            ILLUMINACLIP:"$9":2:30:10 \
            LEADING:10 TRAILING:10 MAXINFO:50:0.97 MINLEN:20
#+end_src
- Reference
  - Trimmomatic parameters based on Taylor's parameters ([[https://mail.google.com/mail/u/0/#search/sundby+fastq/FMfcgzGmvLWSbsmhDsffvSSWfjWdQhhR?projector=1&messagePartId=0.1][email]])
  - https://github.com/AAFC-BICoE/snakemake-trimmomatic/blob/master/Snakefile
***** FastQC                                                       :smk_rule:
- Snakemake
  #+begin_src snakemake
rule fastqc_raw:
    input: 
        config["raw_fq_dir"] + "/{fq_id}_{read}.fastq.gz",
    params: 
        out_dir = config["qc_dir"],
    output:
        html = config["qc_dir"] + "/{fq_id}_{read}_fastqc.html", 
        zip = config["qc_dir"] + "/{fq_id}_{read}_fastqc.zip", 
    log: 
        config["log_dir"] + "/fastqc_raw_{fq_id}_{read}.log",
    shell:
        """
	fastqc --outdir {params.out_dir} \
	--quiet \
	--threads {config[threads]} {input} &> {log}
        """
#+end_src
- Snakemake
  #+begin_src snakemake
rule fastqc_proc:
    input: 
        config["processed_fq_dir"] + "/{fq_id}_proc_{read}.fastq.gz",
    params: 
        out_dir = config["qc_dir"],
    output:
        html = config["qc_dir"] + "/{fq_id}_proc_{read}_fastqc.html", 
        zip = config["qc_dir"] + "/{fq_id}_proc_{read}_fastqc.zip", 
    log: 
        config["log_dir"] + "/fastqc_raw_{fq_id}_{read}.log",
    shell:
        """
	fastqc --outdir {params.out_dir} \
	--quiet \
	--threads {config[threads]} {input} &> {log}
        """
#+end_src
- https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html see multiext
- [[file:./workflows/scripts/fastqc.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/fastqc.sh
fastqc --outdir $2 \
       --quiet \
       --threads $3 $1
#+end_src
**** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
rule all:
    input:

rule fastqc:
    input: 
        raw = config["fastq_dir"] + "/{fastq_id}.faster.gz"
        processed = config
    output:
    shell:
    """
    fastqc
    """

rule seq_preprocess:
    input:
    output:
    shell:
        """
        trimmomatic
        """

**** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
***** Ideas
  - filter to min file size && expected by manual spreadsheet
  - fastqs too small (< 500 Mb)
    #+begin_src bash :results replace
  find /mnt/ris/aadel/mpnst/inputs/cappseq-fastq -size -500M
  #+end_src


** TODO Alignment 
ref=/fdb/igenomes/Homo_sapiens/UCSC/hg19/Sequence/BWAIndex/genome.fa /fdb/genome/GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.fna
RG="@RG\tID:${sampleName}\tLB:${sampleName}\tSM:${sampleName}\tPL:ILLUMINA"
bwa mem -M -t 32 -R "$RG" $ref ${sampleName}_trim_R1.fastq ${sampleName}_trim_R2.fastq>${sampleName}.sam
java -Xmx60g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar  SortSam INPUT=${sampleName}.sam OUTPUT=${sampleName}.bam SORT_ORDER=coordinate
samtools index ${sampleName}.bam ${sampleName}.bam.bai
samtools flagstat ${sampleName}.bam  >${sampleName}.flagstat.txt
java -Xmx60g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar   MarkDuplicates I=${sampleName}.bam O=${sampleName}.dd.bam REMOVE_DUPLICATES=true M=${sampleName}.matrix.txt AS=true VALIDATION_STRINGENCY=LENIENT
samtools index ${sampleName}.dd.bam ${sampleName}.dd.bam.bai
rm ${sampleName}_trim_*.fastq
cd ..

*** Align and dedup
:PROPERTIES:
:CREATED:  [2020-08-16 Sun 16:46]
:ID:       69cae6db-8483-4944-8831-9eafe158cf95
:END:
:LOGBOOK:
CLOCK: [2020-09-08 Tue 09:46]--[2020-09-08 Tue 14:26] =>  4:40
:END:
- bam processing
  #+name: bam_processing
  #+begin_src bash :tangle no
#########1#########2#########3#########4#########5#########6#########7#########8
# 
# Setup 
##
## Docker
if [ -f /.dockerenv ]; then
    echo "shell already in docker, exiting"
    exit 1
fi
source ~/repos/mpnst/bin/local-setup.sh 
docker_interactive
biotools
##
## Local parameters
fastqdir=$localdata/fastqs
bamdir=$localdata/bams
mkdir -p $bamdir
hg19=/drive3/users/jszymanski/data/ref/bwa-hg19/hg19.fa
##
## Functions
bam_processing() {
    # $1 = fastq read 1 ending in _R1.fastq.gz
    # $2 = bam directory
    # $3 = reference fasta
    # $4 = fastq directory
    # $5 = cores
    base=`basename -s _R1.fastq.gz $1`
    # If no alignment files exist, then run full alignment, dedup, sort, and index
    if [ -f "$2/${base}.dedup.sorted.bam" ] &&
           [ -f "$2/${base}.dedup.sorted.bam.bai" ]; then
        echo $base bam processing complete
        rm -f $2/${base}.sam        
        rm -f $2/${base}.bam
        rm -f $2/${base}.dedup.bam
    elif
        # ...
        [ -f "$2/${base}.dedup.sorted.bam" ] &&
            [ ! -f "$2/${base}.dedup.sorted.bam.bai" ]; then
        sambamba index -t $5 $2/${base}.dedup.sorted.bam
        rm -f $2/${base}.sam        
        rm -f $2/${base}.bam
        rm -f $2/${base}.dedup.bam
    elif
        # ...
        [ -f "$2/${base}.dedup.bam" ] &&
            [ ! -f "$2/${base}.dedup.sorted.bam" ]; then
        sambamba sort -t $5 $2/${base}.dedup.bam -o $2/${base}.dedup.sorted.bam
        sambamba index -t $5 $2/${base}.dedup.sorted.bam
        rm -f $2/${base}.sam        
        rm -f $2/${base}.bam
        rm -f $2/${base}.dedup.bam
    elif
        # ...
        [ -f "$2/${base}.bam" ] &&
            [ ! -f "$2/${base}.dedup.bam" ] &&
            [ ! -f "$2/${base}.dedup.sorted.bam" ]; then
        sambamba markdup -r -t $5 $2/${base}.bam $2/${base}.dedup.bam
        sambamba sort -t $5 $2/${base}.dedup.bam -o $2/${base}.dedup.sorted.bam
        sambamba index -t $5 $2/${base}.dedup.sorted.bam
        rm -f $2/${base}.sam        
        rm -f $2/${base}.bam
        rm -f $2/${base}.dedup.bam
    elif
        # If only sam exists, then run dedup, sort, and index
        [ -f "$2/${base}.sam" ] &&
            [ ! -f "$2/${base}.bam" ] &&
            [ ! -f "$2/${base}.dedup.bam" ] &&
            [ ! -f "$2/${base}.dedup.sorted.bam" ]; then
        sambamba view -t $5 -S -f bam $2/${base}.sam > $2/${base}.bam
        sambamba markdup -r -t $5 $2/${base}.bam $2/${base}.dedup.bam
        sambamba sort -t $5 $2/${base}.dedup.bam -o $2/${base}.dedup.sorted.bam
        sambamba index -t $5 $2/${base}.dedup.sorted.bam
        rm -f $2/${base}.sam        
        rm -f $2/${base}.bam
        rm -f $2/${base}.dedup.bam
    else
        bwa mem \
            -t $5 \
            $3 \
            $4/${base}_R1.fastq.gz \
            $4/${base}_R2.fastq.gz > $2/${base}.sam
        sambamba view -t $5 -S -f bam $2/${base}.sam > $2/${base}.bam
        sambamba markdup -r -t $5 $2/${base}.bam $2/${base}.dedup.bam
        sambamba sort -t $5 $2/${base}.dedup.bam -o $2/${base}.dedup.sorted.bam
        sambamba index -t $5 $2/${base}.dedup.sorted.bam
        rm -f $2/${base}.sam        
        rm -f $2/${base}.bam
        rm -f $2/${base}.dedup.bam
    fi
}
# 
#########1#########2#########3#########4#########5#########6#########7#########8
# test
#bam_processing /mnt/xt3/mpnst/fastqs/lib249_R1.fastq.gz $bamdir $hg19 $fastqdir 30
#
for file in $fastqdir/*_R1.fastq.gz; do
    bam_processing $file $bamdir $hg19 $fastqdir 30
done
#
bam_processing $localdata/fastqs/lib168_R1.fastq.gz $bamdir $hg19 $fastqdir 30
#+end_src
- bam special processing for nci-provided bams
  #+name: bam_special_processing_nci_provided_bams
  #+begin_src bash :tangle no  
#!/bin/bash
#
### BAM SPECIAL PROCESSING FOR NCI-PROVIDED BAMS ###
#
# Setup 
##
## Docker
if [ -f /.dockerenv ]; then
    echo "shell already in docker, exiting"
    exit 1
fi
source ~/repos/mpnst/bin/local-setup.sh 
docker_interactive
biotools
##
## Parameters
localdata=/mnt/xt3/mpnst
fastqdir=$localdata/fastqs
bamdir=$localdata/bams
mkdir -p $bamdir
hg19=/drive3/users/jszymanski/data/ref/bwa-hg19/hg19.fa
##
# 
#########1#########2#########3#########4#########5#########6#########7#########8

#
# Pass array of NCI-provided bams
ncibams=(lib210 lib211 lib212 lib213 lib214 lib215 lib216 lib217 lib218 lib219 lib220 lib221 lib222 lib223 lib224 lib225 lib226 lib227 lib228 lib229 lib230 lib231 lib232 lib233 lib 234 lib235 lib236 lib237)
#
#
for file in "${ncibams[@]}"; do
    if [ -f "$bamdir/${file}.dedup.sorted.bam" ] &&
           [ -f "$bamdir/${file}.dedup.sorted.bam.bai" ]; then
        echo $base bam processing complete
        rm -f $bamdir/${file}.dedup.bam
    elif
        # ...
        [ -f "$bamdir/${file}.dedup.sorted.bam" ] &&
            [ ! -f "$bamdir/${file}.dedup.sorted.bam.bai" ]; then
        sambamba index -t 30 $bamdir/${file}.dedup.sorted.bam
        rm -f $bamdir/${file}.dedup.bam
    elif
        # ...
        [ -f "$bamdir/${file}.dedup.bam" ] &&
            [ ! -f "$bamdir/${file}.dedup.sorted.bam" ]; then
        sambamba sort -t 30 $bamdir/${file}.dedup.bam -o $bamdir/${file}.dedup.sorted.bam
        sambamba index -t 30 $bamdir/${file}.dedup.sorted.bam
        rm -f $bamdir/${file}.dedup.bam
    else
        echo done
    fi
done

# Start bam processing as sort
#+end_src
- ideas
  - add # # TODO setup via fastqc metrics check
    - # for read1 in $fastqdir/*_R1.fastq.gz; do
      #     base=`basename -s _R1.fastq.gz ${read1}`
      #     filesize=$(wc -c <"$bamdir/${base}.bam")
      #     if [ $minimum_bam_size -ge $filesize ]; then
      #         echo $base >> /drive3/users/jszymanski/repos/mpnst/data/small_bams        
      #     fi
      # done
      # readarray -t small_bam < /drive3/users/jszymanski/repos/mpnst/data/small_bams         

*** [[file:./workflow/align.smk][Snakefile]]:smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/align.smk
:END:              
**** Smk preamble
#+begin_src snakemake
configfile: "./config/common.yaml"            
#+end_src              
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        config["inputs_dir"] + "/" + config["hg38_fasta"],
        config["inputs_dir"] + "/" + config["hg38_bwa_index_zip"],
        config["ref_dir"] + "/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.amb",
        config["ref_dir"] + "/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.ann",
        config["ref_dir"] + "/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bwt",
        config["ref_dir"] + "/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.sa",	
#+end_src                            
***** Get fasta and index                                          :smk_rule:
- [[file:/mnt/ris/aadel/mpnst/logs/get_fasta.log][Log file]]
- Snakemake
  #+begin_src snakemake
rule get_fasta:
    log: config["log_dir"] + "/get_fasta.log"
    output:
        hg38_fasta = config["inputs_dir"] + "/" + config["hg38_fasta"],
        hg38_bwa_index_zip = config["inputs_dir"] + "/" + config["hg38_bwa_index_zip"],
    shell:
        """
        wget {config[hg38_fasta_ftp]} -P {config[inputs_dir]}
        wget {config[hg38_bwa_index_ftp]} -P {config[inputs_dir]}
        tar -xzf {config[inputs_dir]}/{config[hg38_bwa_index_zip]} -C {config[ref_dir]}
        """
#+end_src
***** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:

****** Align                                                       :smk_rule:
- Snakemake
#+begin_src snakemake
rule align:
    input:
    output:
    shell:
        """
        scripts/align.sh
        """
#+end_src
- [[file:./workflows/scripts/align.sh][Base script]]
#+begin_src bash :tangle ./workflows/scripts/align.sh
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8               
###
###    SCRIPT TITLE   ###                
###

#+end_src
**** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
*** TODO hg38 - https://mail.google.com/mail/u/0/#inbox/FMfcgzGmvLWSbsmhDsffvSSWfjWdQhhR
** TODO Alignment QC
** TODO Downsample Bams
#+name: downsample_bam
#+begin_src bash :tangle ./src/functions.sh
function downsample_bam {

## Calculate the sampling factor based on the intended number of reads:
FACTOR=$(samtools idxstats $1 | cut -f3 | awk -v COUNT=$2 'BEGIN {total=0} {total += $1} END {print COUNT/total}')

if [[ $FACTOR > 1 ]]; then 
    echo "DS reads exceeds total for $1"
else
    sambamba view -s $FACTOR -f bam -l 5 $1    
fi
}

#+end_src

#+name: downsample_bam
#+begin_src bash :tangle ./src/functions.sh
function downsample_bam {

## Calculate the sampling factor based on the intended number of reads:
FACTOR=$(samtools idxstats $1 | cut -f3 | awk -v COUNT=$2 'BEGIN {total=0} {total += $1} END {print COUNT/total}')

if [[ $FACTOR > 1 ]]; then 
    echo "DS reads exceeds total for $1"
else
    sambamba view -s $FACTOR -f bam -l 5 $1    
fi
}

#+end_src

* Local Variables
#+TODO: WAITING(w@) TODO(t) INPROCESS(p) | CLOSEOUT DONE(d!) DELEGATED(@) CANCELED(@)  
#+PROPERTY: LOGGING nil
#+PROPERTY: header-args:bash :tangle-mode (identity #o777)
#+property: header-args    :cache yes
#+property: header-args    :exports none            
#+property: header-args    :eval never-export
#+property: header-args    :results silent            
#+property: header-args    :tangle no
#+startup: shrink




